{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-05-10T08:50:56.731976Z",
          "iopub.execute_input": "2023-05-10T08:50:56.732374Z",
          "iopub.status.idle": "2023-05-10T08:51:12.600705Z",
          "shell.execute_reply.started": "2023-05-10T08:50:56.732343Z",
          "shell.execute_reply": "2023-05-10T08:51:12.599524Z"
        },
        "trusted": true,
        "id": "58zE4hAF9Xyz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import zipfile\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-10T08:51:12.603095Z",
          "iopub.execute_input": "2023-05-10T08:51:12.603436Z",
          "iopub.status.idle": "2023-05-10T08:51:12.608924Z",
          "shell.execute_reply.started": "2023-05-10T08:51:12.603405Z",
          "shell.execute_reply": "2023-05-10T08:51:12.607563Z"
        },
        "trusted": true,
        "id": "aMxwhSXI9Xy2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract_data():\n",
        "\n",
        " url = 'http://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip'\n",
        " urllib.request.urlretrieve(url, 'germantrafficsigns.zip')\n",
        " with zipfile.ZipFile('germantrafficsigns.zip', 'r') as zip_ref:\n",
        "\n",
        "  zip_ref.extractall()\n"
      ],
      "metadata": {
        "id": "XaSZBt9Y9gUF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess(image, label):\n",
        "\n",
        " image=image/255  # NORMALIZING IMAGES (RESCALING)\n",
        " return image, label\n",
        "\n",
        "\n",
        "# SOLUTION_MODEL()  loads the data, normalizes and resizes the images, splits it into\n",
        "# train and validation sets, defines the model, compiles it and finally\n",
        "# trains the model. \n",
        "\n",
        "def solution_model(): # trained model is returned from this function\n",
        "   \n",
        "  \n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "    IMG_SIZE = (30,30)\n",
        "\n",
        "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory='/kaggle/input/german-traffic-signs/train',\n",
        "        label_mode='categorical',\n",
        "        image_size= IMG_SIZE,\n",
        "        batch_size = BATCH_SIZE)\n",
        "\n",
        "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory='/kaggle/input/german-traffic-signs/validation',\n",
        "        label_mode='categorical',\n",
        "        image_size= IMG_SIZE ,\n",
        "        batch_size = BATCH_SIZE)\n",
        "\n",
        "# Normalizes train and validation datasets using the preprocess() function.\n",
        "\n",
        "    train_ds = train_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
        "        tf.data.experimental.AUTOTUNE)\n",
        "    val_ds = val_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#   define the model\n",
        "    \n",
        "    model = tf.keras.models.Sequential([  # ADD LAYERS OF THE MODEL HERE\n",
        "    tf.keras.layers.Conv2D(filters=56,kernel_size=(3,3),activation='relu',input_shape=(30,30,3)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(43, activation='softmax')\n",
        "])\n",
        "\n",
        "#  compile and train the model\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "      \n",
        "    model.fit(train_ds, validation_data=val_ds, epochs=20, batch_size=BATCH_SIZE)\n",
        "      \n",
        "    return model\n",
        "\n",
        "\n",
        "# save model\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "   # model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-10T08:53:55.645139Z",
          "iopub.execute_input": "2023-05-10T08:53:55.645581Z"
        },
        "trusted": true,
        "id": "wdYeFpr99Xy2",
        "outputId": "331eb7f1-40d8-461b-ba15-b387ff999480"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 31367 files belonging to 43 classes.\nFound 7842 files belonging to 43 classes.\nEpoch 1/20\n981/981 [==============================] - 67s 67ms/step - loss: 0.8417 - accuracy: 0.7804 - val_loss: 0.3134 - val_accuracy: 0.9051\nEpoch 2/20\n981/981 [==============================] - 60s 61ms/step - loss: 0.1844 - accuracy: 0.9520 - val_loss: 0.2132 - val_accuracy: 0.9408\nEpoch 3/20\n981/981 [==============================] - 62s 63ms/step - loss: 0.1081 - accuracy: 0.9700 - val_loss: 0.1501 - val_accuracy: 0.9620\nEpoch 4/20\n981/981 [==============================] - 61s 62ms/step - loss: 0.0801 - accuracy: 0.9781 - val_loss: 0.1832 - val_accuracy: 0.9543\nEpoch 5/20\n981/981 [==============================] - 62s 63ms/step - loss: 0.0648 - accuracy: 0.9825 - val_loss: 0.1757 - val_accuracy: 0.9625\nEpoch 6/20\n981/981 [==============================] - 61s 62ms/step - loss: 0.0502 - accuracy: 0.9863 - val_loss: 0.1783 - val_accuracy: 0.9605\nEpoch 7/20\n851/981 [=========================>....] - ETA: 7s - loss: 0.0423 - accuracy: 0.9882",
          "output_type": "stream"
        }
      ]
    }
  ]
}